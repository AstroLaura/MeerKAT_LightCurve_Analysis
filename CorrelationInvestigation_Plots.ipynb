{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for analysing the systematics in the GX 339-4 field\n",
    "\n",
    "These are the plots for investigating the systematics in the light curves in the GX 339-4 field. You will need the light curves of all of the sources (in Pandas csv format), and the results of correlating all of the sources together for each subband. Please see my report/thesis for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"figure.figsize\": (12,9),\n",
    "          \"font.size\": 20,\n",
    "          \"font.weight\": \"normal\",\n",
    "          \"xtick.major.size\": 9,\n",
    "          \"xtick.minor.size\": 4,\n",
    "          \"ytick.major.size\": 9,\n",
    "          \"ytick.minor.size\": 4,\n",
    "          \"xtick.major.width\": 4,\n",
    "          \"xtick.minor.width\": 3,\n",
    "          \"ytick.major.width\": 4,\n",
    "          \"ytick.minor.width\": 3,\n",
    "          \"xtick.major.pad\": 8,\n",
    "          \"xtick.minor.pad\": 8,\n",
    "          \"ytick.major.pad\": 8,\n",
    "          \"ytick.minor.pad\": 8,\n",
    "          \"lines.linewidth\": 3,\n",
    "          \"lines.markersize\": 10,\n",
    "          \"axes.linewidth\": 4,\n",
    "          \"legend.loc\": \"best\",\n",
    "          \"text.usetex\": False,    \n",
    "          \"xtick.labelsize\" : 20,\n",
    "          \"ytick.labelsize\" : 20,\n",
    "          }\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from datetime import date\n",
    "import subprocess as sub\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.stats as spstats\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from astropy import units as un\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.time\n",
    "from astropy.io import fits\n",
    "from astropy import nddata\n",
    "from astropy.wcs import WCS\n",
    "from astropy.timeseries import LombScargle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['legend.loc'] = 'best'\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annulus_outer_r(inner_r, area):\n",
    "    '''\n",
    "    Get the outer radius of an annulus of specified area\n",
    "    \n",
    "    Takes the inner radius of the annulus and\n",
    "    the required area of the annulus and\n",
    "    calculates the outer radius corresponding\n",
    "    to those values\n",
    "    \n",
    "    Args:\n",
    "    inner_r (float): the inner radius of the\n",
    "                     annulus\n",
    "    area (float): the area of the annulus\n",
    "    \n",
    "    Returns:\n",
    "    The outer radius of the annulus (float)\n",
    "    '''\n",
    "    if inner_r == 0:\n",
    "        outer_r = np.sqrt(area/np.pi)\n",
    "    else:\n",
    "        outer_r = np.sqrt((area/np.pi) + inner_r**2.)\n",
    "        \n",
    "    return outer_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some useful parameters and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to where files/plots will be saved\n",
    "file_path = ('/raid/driessen/FlareStars/'\n",
    "             'GX339/Correlation_Investigation/')\n",
    "\n",
    "# The TraP database name\n",
    "db = 'Laura_NWLayers_ReProc'\n",
    "\n",
    "# The path to the source light curves you want\n",
    "# to use\n",
    "lightcurve_path = ('/raid/driessen/FlareStars/'\n",
    "                   'GX339/Source_Light_Curves/'\n",
    "                   'Average_Scaled/')\n",
    "\n",
    "# The dataset ID values (from TraP) and\n",
    "# the corresponding central frequencies (MHz)\n",
    "DSs = [49, 52, 53, 50, 54, 55, 51, 33]\n",
    "freqs = [1658, 1551, 1444, 1337, 1123, 1016, 909, 'MFS']\n",
    "\n",
    "# The names of the columns you want\n",
    "# to use in the pandas tables\n",
    "mjd_col = 'mjd'\n",
    "flux_col = 'f_int_median_scaled'\n",
    "flux_err_col = 'f_int_median_scaled_err'\n",
    "freq_col = 'freq_eff_int'\n",
    "pc_col = 'dist_to_pc_DEG'\n",
    "\n",
    "# If you're using the light curve files with\n",
    "# all extended sources removed, this should\n",
    "# be 'PS', otherwise it should be 'ES'\n",
    "ext = 'PS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify known variable sources\n",
    "\n",
    "Here we find the running catalogue (from TraP) numbers for the three known variables in the GX 339-4 field: GX 339-4 itself (GX), MKT J170456.2-482100 (fb), and PSR J1703-4851 (psr). This part takes a little bit to run.\n",
    "\n",
    "We'll also set up some useful plotting variables for these three sources, which we'll use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{49: 141818, 52: 158069, 53: 163204, 50: 148317, 54: 167758, 55: 174325, 51: 152406, 33: 63902}\n",
      "{49: 140362, 52: 156014, 53: 161507, 50: 145520, 54: 166390, 55: 171657, 51: 151187, 33: 62347}\n",
      "{49: 141276, 52: 156642, 53: 161849, 50: 146870, 54: 166972, 55: 172730, 51: 151623, 33: 63193}\n"
     ]
    }
   ],
   "source": [
    "# Set up the coordinates of the variable sources\n",
    "fb = SkyCoord(np.array([[256.23450507,\n",
    "                         -48.35008655]]),\n",
    "              unit=(un.degree, un.degree))\n",
    "gx = SkyCoord(np.array([[255.70567674,\n",
    "                         -48.78963475]]),\n",
    "              unit=(un.degree, un.degree))\n",
    "psr = SkyCoord(np.array([[255.97732915,\n",
    "                          -48.86685808]]),\n",
    "               unit=(un.degree, un.degree))\n",
    "\n",
    "fb_rcats = {}\n",
    "gx_rcats = {}\n",
    "psr_rcats = {}\n",
    "\n",
    "# Search all of the light curves to identify the running catalogue\n",
    "# of each source in each data set\n",
    "for d, ds in enumerate(DSs):\n",
    "    all_lcs = all_lcs = glob.glob(('{0}rcat*'\n",
    "                                       'db{1}_ds{2}_'\n",
    "                                       '{3}.csv').format(lightcurve_path,\n",
    "                                                         db,\n",
    "                                                         ds, ext))\n",
    "    \n",
    "    for lcf in all_lcs:\n",
    "        lc = pd.read_csv(lcf)\n",
    "        ra = np.nanmean(lc['ra'])\n",
    "        dec = np.nanmean(lc['decl'])\n",
    "        lc_coord = SkyCoord(np.array([[ra,\n",
    "                                       dec]]),\n",
    "                            unit=(un.degree,\n",
    "                                  un.degree))\n",
    "        \n",
    "        fb_sep = lc_coord.separation(fb)\n",
    "        gx_sep = lc_coord.separation(gx)\n",
    "        psr_sep = lc_coord.separation(psr)\n",
    "        \n",
    "        if fb_sep.deg < 2./60./60.:\n",
    "            fb_rcats[ds] = np.array(lc['runcat'])[0]\n",
    "        elif gx_sep.deg < 2./60./60.:\n",
    "            gx_rcats[ds] = np.array(lc['runcat'])[0]\n",
    "        elif psr_sep.deg < 2./60./60.:\n",
    "            psr_rcats[ds] = np.array(lc['runcat'])[0]\n",
    "\n",
    "print(fb_rcats)\n",
    "print(gx_rcats)\n",
    "print(psr_rcats)\n",
    "\n",
    "\n",
    "# Set up some useful plotting variables\n",
    "fb_col = '#E0777D'\n",
    "gx_col = '#46B1C9'\n",
    "psr_col = '#645DD7'\n",
    "\n",
    "fb_mark = 'v'\n",
    "gx_mark = 'd'\n",
    "psr_mark = '^'\n",
    "\n",
    "pointsize=5\n",
    "fb_frame = mlines.Line2D([], [], color='None', marker=fb_mark,\n",
    "                       markerfacecolor='None',\n",
    "                       markeredgecolor=fb_col,\n",
    "                       markersize=pointsize+5,\n",
    "                       label='MKT J170456.2-482100')\n",
    "gx_frame = mlines.Line2D([], [], color='None', marker=gx_mark,\n",
    "                       markerfacecolor='None',\n",
    "                       markeredgecolor=gx_col,\n",
    "                       markersize=pointsize+5,\n",
    "                       label='GX 339-4')\n",
    "psr_frame = mlines.Line2D([], [], color='None', marker=psr_mark,\n",
    "                       markerfacecolor='None',\n",
    "                       markeredgecolor=psr_col,\n",
    "                       markersize=pointsize+5,\n",
    "                       label='PSR J1703-4851')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the models of the systematics\n",
    "\n",
    "Here we plot the median and MAD (left column), and mean and standard deviation (right column) models of the systematics in the light curves in each subband and MFS. We also compare including the resolved and artefact sources ('ES') and excluding those sources ('PS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 2, figsize=(16, 24), sharex=True, sharey='row')\n",
    "cols = ['Black', 'Grey']\n",
    "fmts = ['o', '.']\n",
    "for d, ds in enumerate(DSs):\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    for e, ext in enumerate(['ES', 'PS']):\n",
    "        all_lcs = all_lcs = glob.glob(('{0}rcat*'\n",
    "                                       'db{1}_ds{2}_'\n",
    "                                       '{3}.csv').format(lightcurve_path,\n",
    "                                                         db,\n",
    "                                                         ds,\n",
    "                                                         ext))\n",
    "        lc = pd.read_csv(all_lcs[0])\n",
    "\n",
    "        median_model = lc['ref scale model median']\n",
    "        median_model_err = lc['ref scale model mad']\n",
    "\n",
    "        mean_model = lc['ref scale model mean']\n",
    "        mean_model_err = lc['ref scale model std']\n",
    "\n",
    "        mjd = lc[mjd_col]\n",
    "\n",
    "        ax[d, 0].errorbar(mjd, median_model,\n",
    "                          yerr=median_model_err,\n",
    "                          fmt=fmts[e], c=cols[e])\n",
    "        ax[d, 1].errorbar(mjd, mean_model,\n",
    "                          yerr=mean_model_err,\n",
    "                          fmt=fmts[e], c=cols[e])\n",
    "\n",
    "    ax_text = AnchoredText(freq_str,\n",
    "                           loc='upper left',\n",
    "                           prop=dict(size=18, color='Grey'),\n",
    "                           borderpad=0.1,\n",
    "                           frameon=False)\n",
    "    ax[d, 0].add_artist(ax_text)\n",
    "\n",
    "    xmin, xmax = ax[d, 0].get_xlim()\n",
    "    ax[d, 0].plot(np.linspace(xmin, xmax, 10), np.ones(10),\n",
    "                  '--', c='DarkGrey', lw=3, alpha=0.5)\n",
    "    ax[d, 0].set_xlim(xmin, xmax)\n",
    "    xmin, xmax = ax[d, 1].get_xlim()\n",
    "    ax[d, 1].plot(np.linspace(xmin, xmax, 10), np.ones(10),\n",
    "                  '--', c='DarkGrey', lw=3, alpha=0.5)\n",
    "    ax[d, 1].set_xlim(xmin, xmax)\n",
    "    \n",
    "    ax[d, 0].set_ylabel('Fractional offset', fontsize=14)\n",
    "\n",
    "    ax[d, 1].tick_params(axis='y', direction='in')\n",
    "    ax[d, 1].tick_params(labelleft=False)\n",
    "    if d < 7:\n",
    "        for col in range(2):\n",
    "            ax[d, col].tick_params(axis='x', direction='in')\n",
    "            ax[d, col].tick_params(labelbottom=False)\n",
    "    \n",
    "ax[0, 0].set_title('Median systematic model', fontsize=18)\n",
    "ax[0, 1].set_title('Mean systematic model', fontsize=18)\n",
    "\n",
    "ax[7, 0].set_xlabel('MJD', fontsize=14)\n",
    "ax[7, 1].set_xlabel('MJD', fontsize=14)\n",
    "\n",
    "pointsize = 5\n",
    "es_dot = mlines.Line2D([], [], color='None', marker='o',\n",
    "                       markerfacecolor='Black',\n",
    "                       markersize=pointsize+5,\n",
    "                       label='Including resolved/artefact sources')\n",
    "ps_dot = mlines.Line2D([], [], color='None', marker='o',\n",
    "                       markerfacecolor='DarkGrey',\n",
    "                       markeredgecolor='DarkGrey',\n",
    "                       markersize=pointsize+5,\n",
    "                       label='Point sources only')\n",
    "one_line = mlines.Line2D([], [], color='DarkGrey', lw=3, alpha=0.7,\n",
    "                         marker='None', linestyle='--',\n",
    "                         label='No change to measured fluxes')\n",
    "\n",
    "leg0 = ax[7, 0].legend(handles=[es_dot, ps_dot, one_line],\n",
    "                       fontsize=15, frameon=True,\n",
    "                       loc='lower left', ncol=3,\n",
    "                       bbox_to_anchor=(0.0, -0.7),\n",
    "                       borderaxespad=0,\n",
    "                       edgecolor='Black')\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "figure_name = ('{0}PSvsES_Models.png').format(file_path)\n",
    "fig.savefig(figure_name, bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the variability parameters\n",
    "\n",
    "Here we are going to plot the variability parameters for every subband and MFS. We are going to do a few variations on the plot, to show different things.\n",
    "\n",
    "### Compare different signal to noise values\n",
    "\n",
    "First we are going to plot the variability parameters showing how the signal to noise of the sources included changes the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/driessen/.conda/envs/LaurasJupyter36/lib/python3.6/site-packages/pandas/core/series.py:679: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/driessen/.conda/envs/LaurasJupyter36/lib/python3.6/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for ext in ['ES', 'PS']:\n",
    "    for flux_col in ['f_int_median',\n",
    "                     'f_int_median_scaled_median']:\n",
    "        if flux_col == 'f_int_median':\n",
    "            eta_col = 'eta_param'\n",
    "            V_col = 'V_param'\n",
    "            mad_col = 'mad_param'\n",
    "        elif flux_col == 'f_int_median_scaled_median':\n",
    "            eta_col = 'median_scaled_eta'\n",
    "            V_col = 'median_scaled_V'\n",
    "            mad_col = 'median_scaled_madp'\n",
    "\n",
    "        fig, ax = plt.subplots(8, 3, figsize=(16, 24), sharex=True, sharey='col')\n",
    "        for d, ds in enumerate(DSs):\n",
    "            freq = freqs[d]\n",
    "            if freq == 'MFS':\n",
    "                freq_str = 'MFS'\n",
    "            else:\n",
    "                freq_str = '{}MHz'.format(freq)\n",
    "            var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                                    'db{1}_ds{2}_{3}.csv'.format(lightcurve_path,\n",
    "                                                                 db,\n",
    "                                                                 ds, ext)))[0]\n",
    "            vp_all = pd.read_csv(var_params)\n",
    "            qry = '`detected SN2` == \\'No\\''\n",
    "            vp_no = vp_all.query(qry)\n",
    "\n",
    "            qry = '`detected SN2` == \\'Yes\\' and `detected SN3` == \\'No\\''\n",
    "            vp_2 = vp_all.query(qry)\n",
    "\n",
    "            qry = '`detected SN3` == \\'Yes\\''\n",
    "            vp_3 = vp_all.query(qry)\n",
    "\n",
    "            dataframes = [vp_no, vp_2, vp_3]\n",
    "            vp_cols = ['#CED2DE', '#5A6587', '#08090C']\n",
    "\n",
    "            for df, dataframe in enumerate(dataframes):\n",
    "                flux = np.log10(dataframe[flux_col])\n",
    "                ax[d, 0].scatter(flux, np.log10(dataframe[eta_col]),\n",
    "                                 marker='.', c=vp_cols[df], s=35)\n",
    "                ax[d, 1].scatter(flux, np.log10(dataframe[V_col]),\n",
    "                                 marker='.', c=vp_cols[df], s=35)\n",
    "                ax[d, 2].scatter(flux, np.log10(dataframe[mad_col]),\n",
    "                                 marker='.', c=vp_cols[df], s=35)\n",
    "\n",
    "            fb_info = vp_all[vp_all['runcat'] == fb_rcats[ds]]\n",
    "            gx_info = vp_all[vp_all['runcat'] == gx_rcats[ds]]\n",
    "            psr_info = vp_all[vp_all['runcat'] == psr_rcats[ds]]\n",
    "            for df, dataframe in enumerate([fb_info,\n",
    "                                            gx_info,\n",
    "                                            psr_info]):\n",
    "                cola = [fb_col, gx_col, psr_col][df]\n",
    "                marka = [fb_mark, gx_mark, psr_mark][df]\n",
    "\n",
    "                ax[d, 0].scatter(np.log10(dataframe[flux_col]),\n",
    "                                 np.log10(dataframe[eta_col]),\n",
    "                                 marker=marka, c='none',\n",
    "                                 edgecolor=cola)\n",
    "\n",
    "                ax[d, 1].scatter(np.log10(dataframe[flux_col]),\n",
    "                                     np.log10(dataframe[V_col]),\n",
    "                                     marker=marka, c='none',\n",
    "                                 edgecolor=cola)\n",
    "\n",
    "                ax[d, 2].scatter(np.log10(dataframe[flux_col]),\n",
    "                                 np.log10(dataframe[mad_col]),\n",
    "                                 marker=marka, c='none',\n",
    "                                 edgecolor=cola)\n",
    "\n",
    "            ax[d, 0].set_ylabel(r'log$_{10}\\eta$', fontsize=14)\n",
    "            ax[d, 1].set_ylabel(r'log$_{10}$V', fontsize=14)\n",
    "            ax[d, 2].set_ylabel(r'log$_{10}\\xi$', fontsize=14)\n",
    "\n",
    "            ax_text = AnchoredText(freq_str,\n",
    "                                   loc='upper left',\n",
    "                                   prop=dict(size=18, color='Grey'),\n",
    "                                   borderpad=0.1,\n",
    "                                   frameon=False)\n",
    "            ax[d, 0].add_artist(ax_text)\n",
    "\n",
    "            if d == 7:\n",
    "                for col in range(3):\n",
    "                    ax[d, col].set_xlabel(r'log$_{10}$Flux [Jy]',\n",
    "                                          fontsize=14)\n",
    "            else:\n",
    "                for col in range(3):\n",
    "                    ax[d, col].tick_params(axis='x', direction='in')\n",
    "                    ax[d, col].tick_params(labelbottom=False)\n",
    "\n",
    "\n",
    "        pointsize = 5\n",
    "        undetected = mlines.Line2D([], [], color='None', marker='.',\n",
    "                                   markerfacecolor=vp_cols[0],\n",
    "                                   markeredgecolor='None',\n",
    "                                   markersize=pointsize+5,\n",
    "                                   label='Light curves with S/N < 2')\n",
    "        less3 = mlines.Line2D([], [], color='None', marker='.',\n",
    "                              markerfacecolor=vp_cols[1],\n",
    "                              markeredgecolor='None',\n",
    "                              markersize=pointsize+5,\n",
    "                              label='Light curves with 2 < S/N < 3')\n",
    "        great3 = mlines.Line2D([], [], color='None', marker='.',\n",
    "                               markerfacecolor=vp_cols[2],\n",
    "                               markeredgecolor='None',\n",
    "                               markersize=pointsize+5,\n",
    "                               label='Light curves with S/N > 3')\n",
    "\n",
    "        leg0 = ax[7, 0].legend(handles=[undetected, less3, great3,\n",
    "                                        fb_frame, gx_frame, psr_frame],\n",
    "                               fontsize=15, frameon=True, loc='lower left', ncol=4,\n",
    "                               bbox_to_anchor= (0.0, -0.7), borderaxespad=0,\n",
    "                               edgecolor='Black')\n",
    "\n",
    "        fig.subplots_adjust(hspace=0, wspace=0.3)\n",
    "\n",
    "        figure_name = ('{0}VarParams_{1}_SNall_{2}.png').format(file_path,\n",
    "                                                                ext,\n",
    "                                                                flux_col)\n",
    "        fig.savefig(figure_name, bbox_inches='tight')\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal to noise 2 only\n",
    "\n",
    "Similar to the above plots, except we're just showing sources above and below a signal to noise of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "signoises = [2, 3]\n",
    "ext = 'PS'\n",
    "flux_col = 'f_int_median'\n",
    "eta_col = 'eta_param'\n",
    "V_col = 'V_param'\n",
    "mad_col = 'mad_param'\n",
    "\n",
    "for signoise in signoises:\n",
    "    fig, ax = plt.subplots(8, 3, figsize=(16, 24), sharex=True, sharey='col')\n",
    "    for d, ds in enumerate(DSs):\n",
    "        freq = freqs[d]\n",
    "        if freq == 'MFS':\n",
    "            freq_str = 'MFS'\n",
    "        else:\n",
    "            freq_str = '{}MHz'.format(freq)\n",
    "        var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                                'db{1}_ds{2}_{3}.csv'.format(lightcurve_path,\n",
    "                                                             db,\n",
    "                                                             ds, ext)))[0]\n",
    "        vp_all = pd.read_csv(var_params)\n",
    "        vp = vp_all[vp_all['detected SN{}'.format(signoise)] == 'Yes']\n",
    "        vp_no = vp_all[vp_all['detected SN{}'.format(signoise)] == 'No']\n",
    "        fb_info = vp[vp['runcat'] == fb_rcats[ds]]\n",
    "        gx_info = vp[vp['runcat'] == gx_rcats[ds]]\n",
    "        psr_info = vp[vp['runcat'] == psr_rcats[ds]]\n",
    "\n",
    "        flux = np.log10(vp_no[flux_col])\n",
    "        ax[d, 0].scatter(flux, np.log10(vp_no[eta_col]),\n",
    "                         marker='.', c='DarkGrey', s=35)\n",
    "        ax[d, 1].scatter(flux, np.log10(vp_no[V_col]),\n",
    "                         marker='.', c='DarkGrey', s=35)\n",
    "        ax[d, 2].scatter(flux, np.log10(vp_no[mad_col]),\n",
    "                         marker='.', c='DarkGrey', s=35)\n",
    "\n",
    "        flux = np.log10(vp[flux_col])\n",
    "        ax[d, 0].scatter(flux, np.log10(vp[eta_col]),\n",
    "                         marker='.', c='Black', s=35)\n",
    "        ax[d, 1].scatter(flux, np.log10(vp[V_col]),\n",
    "                         marker='.', c='Black', s=35)\n",
    "        ax[d, 2].scatter(flux, np.log10(vp[mad_col]),\n",
    "                         marker='.', c='Black', s=35)\n",
    "\n",
    "        for df, dataframe in enumerate([fb_info,\n",
    "                                        gx_info,\n",
    "                                        psr_info]):\n",
    "            cola = [fb_col, gx_col, psr_col][df]\n",
    "            marka = [fb_mark, gx_mark, psr_mark][df]\n",
    "\n",
    "            ax[d, 0].scatter(np.log10(dataframe[flux_col]),\n",
    "                             np.log10(dataframe[eta_col]),\n",
    "                             marker=marka, c='none',\n",
    "                             edgecolor=cola)\n",
    "\n",
    "            ax[d, 1].scatter(np.log10(dataframe[flux_col]),\n",
    "                                 np.log10(dataframe[V_col]),\n",
    "                                 marker=marka, c='none',\n",
    "                             edgecolor=cola)\n",
    "\n",
    "            ax[d, 2].scatter(np.log10(dataframe[flux_col]),\n",
    "                             np.log10(dataframe[mad_col]),\n",
    "                             marker=marka, c='none',\n",
    "                             edgecolor=cola)\n",
    "\n",
    "        ax[d, 0].set_ylabel(r'log$_{10}\\eta$', fontsize=14)\n",
    "        ax[d, 1].set_ylabel(r'log$_{10}$V', fontsize=14)\n",
    "        ax[d, 2].set_ylabel(r'log$_{10}\\xi$', fontsize=14)\n",
    "\n",
    "        ax_text = AnchoredText(freq_str,\n",
    "                               loc='upper left',\n",
    "                               prop=dict(size=18, color='Grey'),\n",
    "                               borderpad=0.1,\n",
    "                               frameon=False)\n",
    "        ax[d, 0].add_artist(ax_text)\n",
    "\n",
    "        if d == 7:\n",
    "            for col in range(3):\n",
    "                ax[d, col].set_xlabel(r'log$_{10}$Flux [Jy]',\n",
    "                                      fontsize=14)\n",
    "        else:\n",
    "            for col in range(3):\n",
    "                ax[d, col].tick_params(axis='x', direction='in')\n",
    "                ax[d, col].tick_params(labelbottom=False)\n",
    "\n",
    "\n",
    "    pointsize = 5\n",
    "    corr_dot = mlines.Line2D([], [], color='None', marker='.',\n",
    "                           markerfacecolor='Black',\n",
    "                           markersize=pointsize+5,\n",
    "                           label='Light curves with S/N > {}'.format(signoise))\n",
    "    uncorr_dot = mlines.Line2D([], [], color='None', marker='.',\n",
    "                           markerfacecolor='DarkGrey',\n",
    "                           markeredgecolor='DarkGrey',\n",
    "                           markersize=pointsize+5,\n",
    "                           label='Light curves with S/N < {}'.format(signoise))\n",
    "\n",
    "    leg0 = ax[7, 0].legend(handles=[corr_dot, uncorr_dot,\n",
    "                                    fb_frame, gx_frame, psr_frame],\n",
    "                           fontsize=15, frameon=True, loc='lower left', ncol=4,\n",
    "                           bbox_to_anchor= (0.0, -0.7), borderaxespad=0,\n",
    "                           edgecolor='Black')\n",
    "\n",
    "    fig.subplots_adjust(hspace=0, wspace=0.3)\n",
    "\n",
    "    figure_name = ('{0}VarParams_{1}_SN{2}_{3}.png').format(file_path, ext,\n",
    "                                                            signoise, flux_col)\n",
    "    fig.savefig(figure_name, bbox_inches='tight')\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare all sources and point sources only\n",
    "\n",
    "Now compare the variability parameters before ('ES') and after ('PS') we remove the resolved and artefact sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658MHz\n",
      "----------\n",
      "1551MHz\n",
      "----------\n",
      "1444MHz\n",
      "----------\n",
      "1337MHz\n",
      "----------\n",
      "1123MHz\n",
      "----------\n",
      "1016MHz\n",
      "----------\n",
      "909MHz\n",
      "----------\n",
      "MFS\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "flux_col = 'f_int_median'\n",
    "eta_col = 'eta_param'\n",
    "V_col = 'V_param'\n",
    "mad_col = 'mad_param'\n",
    "exts = ['ES', 'PS']\n",
    "ext_cols = ['DarkGrey', 'Black']\n",
    "\n",
    "fig, ax = plt.subplots(8, 3, figsize=(16, 24), sharex=True, sharey='col')\n",
    "for d, ds in enumerate(DSs):\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "\n",
    "    for e, ext in enumerate(exts):\n",
    "        ecol = ext_cols[e]\n",
    "        var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                                'db{1}_'\n",
    "                                'ds{2}_'\n",
    "                                '{3}.csv'.format(lightcurve_path,\n",
    "                                                 db,\n",
    "                                                 ds, ext)))[0]\n",
    "        vp_all = pd.read_csv(var_params)\n",
    "        vp = vp_all[vp_all['detected SN2'] == 'Yes']\n",
    "\n",
    "        flux = np.log10(vp[flux_col])\n",
    "        ax[d, 0].scatter(flux, np.log10(vp[eta_col]),\n",
    "                         marker='.', c=ecol, s=35)\n",
    "        ax[d, 1].scatter(flux, np.log10(vp[V_col]),\n",
    "                         marker='.', c=ecol, s=35)\n",
    "        ax[d, 2].scatter(flux, np.log10(vp[mad_col]),\n",
    "                         marker='.', c=ecol, s=35)\n",
    "\n",
    "    \n",
    "    fb_info = vp_all[vp_all['runcat'] == fb_rcats[ds]]\n",
    "    gx_info = vp_all[vp_all['runcat'] == gx_rcats[ds]]\n",
    "    psr_info = vp_all[vp_all['runcat'] == psr_rcats[ds]]\n",
    "    for df, dataframe in enumerate([fb_info,\n",
    "                                    gx_info,\n",
    "                                    psr_info]):\n",
    "        cola = [fb_col, gx_col, psr_col][df]\n",
    "        marka = [fb_mark, gx_mark, psr_mark][df]\n",
    "\n",
    "        ax[d, 0].scatter(np.log10(dataframe[flux_col]),\n",
    "                         np.log10(dataframe[eta_col]),\n",
    "                         marker=marka, c='none',\n",
    "                         edgecolor=cola)\n",
    "\n",
    "        ax[d, 1].scatter(np.log10(dataframe[flux_col]),\n",
    "                         np.log10(dataframe[V_col]),\n",
    "                         marker=marka, c='none',\n",
    "                         edgecolor=cola)\n",
    "\n",
    "        ax[d, 2].scatter(np.log10(dataframe[flux_col]),\n",
    "                         np.log10(dataframe[mad_col]),\n",
    "                         marker=marka, c='none',\n",
    "                         edgecolor=cola)\n",
    "\n",
    "    ax[d, 0].set_ylabel(r'log$_{10}\\eta$', fontsize=14)\n",
    "    ax[d, 1].set_ylabel(r'log$_{10}$V', fontsize=14)\n",
    "    ax[d, 2].set_ylabel(r'log$_{10}\\xi$', fontsize=14)\n",
    "\n",
    "    ax_text = AnchoredText(freq_str,\n",
    "                           loc='upper left',\n",
    "                           prop=dict(size=18, color='Grey'),\n",
    "                           borderpad=0.1,\n",
    "                           frameon=False)\n",
    "    ax[d, 0].add_artist(ax_text)\n",
    "    \n",
    "    if d == 7:\n",
    "        for col in range(3):\n",
    "            ax[d, col].set_xlabel(r'log$_{10}$Flux [Jy]',\n",
    "                                  fontsize=14)\n",
    "    else:\n",
    "        for col in range(3):\n",
    "            ax[d, col].tick_params(axis='x', direction='in')\n",
    "            ax[d, col].tick_params(labelbottom=False)\n",
    "\n",
    "    print(freq_str)\n",
    "    print('----------')\n",
    "    \n",
    "    \n",
    "pointsize = 5\n",
    "ps_dot = mlines.Line2D([], [], color='None', marker='.',\n",
    "                       markerfacecolor='Black',\n",
    "                       markersize=pointsize+5,\n",
    "                       label='Point sources only')\n",
    "es_dot = mlines.Line2D([], [], color='None', marker='.',\n",
    "                       markerfacecolor='DarkGrey',\n",
    "                       markeredgecolor='DarkGrey',\n",
    "                       markersize=pointsize+5,\n",
    "                       label='All sources')\n",
    "\n",
    "leg0 = ax[7, 0].legend(handles=[es_dot,\n",
    "                                ps_dot,\n",
    "                                fb_frame,\n",
    "                                gx_frame,\n",
    "                                psr_frame],\n",
    "                       fontsize=15, frameon=True,\n",
    "                       loc='lower left', ncol=4,\n",
    "                       bbox_to_anchor= (0.0, -0.7),\n",
    "                       borderaxespad=0,\n",
    "                       edgecolor='Black')\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0.3)\n",
    "\n",
    "figure_name = ('{0}VarParams_'\n",
    "               'ESvsPS_SN2.png').format(file_path,\n",
    "                                        ext)\n",
    "fig.savefig(figure_name, bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the variability parameters before and after corrrection\n",
    "\n",
    "Similar to the plots above, except comparing the uncorrected and corrected variability parameters for sources with S/N>2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ext = 'PS'\n",
    "fig, ax = plt.subplots(8, 3, figsize=(16, 24), sharex=True, sharey='col')\n",
    "for d, ds in enumerate(DSs):\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                            'db{1}_ds{2}_{3}.csv'.format(lightcurve_path,\n",
    "                                                         db,\n",
    "                                                         ds, ext)))[0]\n",
    "    vp_all = pd.read_csv(var_params)\n",
    "    vp = vp_all[vp_all['detected SN2'] == 'Yes']\n",
    "    fb_info = vp[vp['runcat'] == fb_rcats[ds]]\n",
    "    gx_info = vp[vp['runcat'] == gx_rcats[ds]]\n",
    "    psr_info = vp[vp['runcat'] == psr_rcats[ds]]\n",
    "    \n",
    "    flux = np.log10(vp['f_int_median'])\n",
    "    ax[d, 0].scatter(flux, np.log10(vp['eta_param']),\n",
    "                     marker='.', c='Grey')\n",
    "    ax[d, 1].scatter(flux, np.log10(vp['V_param']),\n",
    "                     marker='.', c='Grey')\n",
    "    ax[d, 2].scatter(flux, np.log10(vp['mad_param']),\n",
    "                     marker='.', c='Grey')\n",
    "\n",
    "    flux = np.log10(vp['f_int_median_scaled_median'])\n",
    "    ax[d, 0].scatter(flux, np.log10(vp['median_scaled_eta']),\n",
    "                     marker='.', c='Black', s=35)\n",
    "    ax[d, 1].scatter(flux, np.log10(vp['median_scaled_V']),\n",
    "                     marker='.', c='Black', s=35)\n",
    "    ax[d, 2].scatter(flux, np.log10(vp['median_scaled_madp']),\n",
    "                     marker='.', c='Black', s=35)\n",
    "\n",
    "    for f, flux_col in enumerate(['f_int_median',\n",
    "                                  'f_int_median_scaled_median']):\n",
    "        eta_col = ['eta_param', 'median_scaled_eta'][f]\n",
    "        V_col = ['V_param', 'median_scaled_V'][f]\n",
    "        mad_col = ['mad_param', 'median_scaled_madp'][f]\n",
    "        for df, dataframe in enumerate([fb_info,\n",
    "                                        gx_info,\n",
    "                                        psr_info]):\n",
    "            cola = [fb_col, gx_col, psr_col][df]\n",
    "            marka = [fb_mark, gx_mark, psr_mark][df]\n",
    "\n",
    "            ax[d, 0].scatter(np.log10(dataframe[flux_col]),\n",
    "                             np.log10(dataframe[eta_col]),\n",
    "                             marker=marka, c='none',\n",
    "                             edgecolor=cola)\n",
    "\n",
    "            ax[d, 1].scatter(np.log10(dataframe[flux_col]),\n",
    "                                 np.log10(dataframe[V_col]),\n",
    "                                 marker=marka, c='none',\n",
    "                             edgecolor=cola)\n",
    "\n",
    "            ax[d, 2].scatter(np.log10(dataframe[flux_col]),\n",
    "                             np.log10(dataframe[mad_col]),\n",
    "                             marker=marka, c='none',\n",
    "                             edgecolor=cola)\n",
    "\n",
    "    ax[d, 0].set_ylabel(r'log$_{10}\\eta$', fontsize=14)\n",
    "    ax[d, 1].set_ylabel(r'log$_{10}$V', fontsize=14)\n",
    "    ax[d, 2].set_ylabel(r'log$_{10}\\xi$', fontsize=14)\n",
    "\n",
    "    ax_text = AnchoredText(freq_str,\n",
    "                           loc='upper left',\n",
    "                           prop=dict(size=18, color='Grey'),\n",
    "                           borderpad=0.1,\n",
    "                           frameon=False)\n",
    "    ax[d, 0].add_artist(ax_text)\n",
    "    \n",
    "    if d == 7:\n",
    "        for col in range(3):\n",
    "            ax[d, col].set_xlabel(r'log$_{10}$Flux [Jy]',\n",
    "                                  fontsize=14)\n",
    "    else:\n",
    "        for col in range(3):\n",
    "            ax[d, col].tick_params(axis='x', direction='in')\n",
    "            ax[d, col].tick_params(labelbottom=False)\n",
    "    \n",
    "    \n",
    "pointsize = 5\n",
    "corr_dot = mlines.Line2D([], [], color='None', marker='.',\n",
    "                       markerfacecolor='Black',\n",
    "                       markersize=pointsize+5,\n",
    "                       label='Corrected light curves')\n",
    "uncorr_dot = mlines.Line2D([], [], color='None', marker='.',\n",
    "                       markerfacecolor='DarkGrey',\n",
    "                       markeredgecolor='DarkGrey',\n",
    "                       markersize=pointsize+5,\n",
    "                       label='Uncorrected light curves')\n",
    "\n",
    "leg0 = ax[7, 0].legend(handles=[uncorr_dot, corr_dot,\n",
    "                                fb_frame, gx_frame, psr_frame],\n",
    "                       fontsize=15, frameon=True, loc='lower left', ncol=3,\n",
    "                       bbox_to_anchor= (0.0, -0.7), borderaxespad=0,\n",
    "                       edgecolor='Black')\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0.3)\n",
    "\n",
    "figure_name = ('{0}UncorrvsCorr_VarParams.png').format(file_path)\n",
    "fig.savefig(figure_name, bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot just the chi-squared parameter\n",
    "\n",
    "Plot the chi-squared parameter for different signal to noise limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for signoise in [2, 3]:\n",
    "    for ext in ['ES', 'PS']:\n",
    "\n",
    "        for flux_col in ['f_int_median', 'f_int_median_scaled_median']:\n",
    "            if flux_col == 'f_int_median':\n",
    "                eta_col = 'eta_param'\n",
    "                V_col = 'V_param'\n",
    "                mad_col = 'mad_param'\n",
    "            elif flux_col == 'f_int_median_scaled_median':\n",
    "                eta_col = 'median_scaled_eta'\n",
    "                V_col = 'median_scaled_V'\n",
    "                mad_col = 'median_scaled_madp'\n",
    "\n",
    "\n",
    "            fig, ax = plt.subplots(4, 2, figsize=(10, 14), sharey=True)\n",
    "            for d, ds in enumerate(DSs):\n",
    "                row = d // 2\n",
    "                col = d % 2\n",
    "\n",
    "                freq = freqs[d]\n",
    "                if freq == 'MFS':\n",
    "                    freq_str = 'MFS'\n",
    "                else:\n",
    "                    freq_str = '{}MHz'.format(freq)\n",
    "                var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                                        'db{1}_ds{2}_{3}.csv'.format(lightcurve_path,\n",
    "                                                                     db,\n",
    "                                                                     ds, ext)))[0]\n",
    "                vp = pd.read_csv(var_params)\n",
    "                vp = vp[vp['detected SN{}'.format(signoise)]=='Yes']\n",
    "\n",
    "                flux = np.log10(vp[flux_col])\n",
    "                ax[row, col].scatter(flux, np.log10(vp[eta_col]),\n",
    "                                     marker='.', c='Black')\n",
    "\n",
    "                fb_info = vp[vp['runcat'] == fb_rcats[ds]]\n",
    "                gx_info = vp[vp['runcat'] == gx_rcats[ds]]\n",
    "                psr_info = vp[vp['runcat'] == psr_rcats[ds]]\n",
    "                for df, dataframe in enumerate([fb_info,\n",
    "                                                gx_info,\n",
    "                                                psr_info]):\n",
    "                    cola = [fb_col, gx_col, psr_col][df]\n",
    "                    marka = [fb_mark, gx_mark, psr_mark][df]\n",
    "\n",
    "                    ax[row, col].scatter(np.log10(dataframe[flux_col]),\n",
    "                                     np.log10(dataframe[eta_col]),\n",
    "                                     marker=marka, c='none',\n",
    "                                     edgecolor=cola)\n",
    "\n",
    "                ax[row, col].set_xlim(-7.7, 0.2)\n",
    "\n",
    "                if col == 0:\n",
    "                    ax[row, col].set_ylabel(r'log$_{10}\\eta$', fontsize=14)\n",
    "                else:\n",
    "                    ax[row, col].tick_params(axis='y', direction='in')\n",
    "\n",
    "                if row == 3:\n",
    "                    for bob in range(2):\n",
    "                        ax[row, bob].set_xlabel(r'log$_{10}$Flux [Jy]',\n",
    "                                              fontsize=14)\n",
    "                else:\n",
    "                    ax[row, col].tick_params(axis='x', direction='in')\n",
    "\n",
    "                ax_text = AnchoredText(freq_str,\n",
    "                                       loc='upper left',\n",
    "                                       prop=dict(size=18, color='Grey'),\n",
    "                                       borderpad=0.1,\n",
    "                                       frameon=False)\n",
    "                ax[row, col].add_artist(ax_text)\n",
    "\n",
    "            pointsize = 5\n",
    "            fb_dot = mlines.Line2D([], [], color='None', marker=fb_mark,\n",
    "                                   markerfacecolor='None',\n",
    "                                   markeredgecolor=fb_col,\n",
    "                                   markersize=pointsize+5,\n",
    "                                   label='MKT J170456.2-482100')\n",
    "            gx_dot = mlines.Line2D([], [], color='None', marker=gx_mark,\n",
    "                                   markerfacecolor='None',\n",
    "                                   markeredgecolor=gx_col,\n",
    "                                   markersize=pointsize+5,\n",
    "                                   label='GX 339-4')\n",
    "            psr_dot = mlines.Line2D([], [], color='None', marker=psr_mark,\n",
    "                                   markerfacecolor='None',\n",
    "                                   markeredgecolor=psr_col,\n",
    "                                   markersize=pointsize+5,\n",
    "                                   label='PSR J1703-4851')\n",
    "\n",
    "            leg0 = ax[3, 0].legend(handles=[fb_dot, gx_dot, psr_dot],\n",
    "                                   fontsize=15, frameon=True, loc='lower left', ncol=2,\n",
    "                                   bbox_to_anchor= (0.0, -0.6), borderaxespad=0,\n",
    "                                   edgecolor='Black')\n",
    "\n",
    "            fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "            figure_name = ('{0}Uncorr_EtaParams_{1}_{2}_SN{3}.png').format(file_path,\n",
    "                                                                           ext,\n",
    "                                                                           flux_col,\n",
    "                                                                           signoise)\n",
    "            fig.savefig(figure_name, bbox_inches='tight')\n",
    "\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot chi-squared vs V\n",
    "\n",
    "Plot the chi-squared parameter against the modulation (V) parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for signoise in [2, 3]:\n",
    "    for ext in ['ES', 'PS']:\n",
    "\n",
    "        for flux_col in ['f_int_median',\n",
    "                         'f_int_median_scaled_median']:\n",
    "            if flux_col == 'f_int_median':\n",
    "                eta_col = 'eta_param'\n",
    "                V_col = 'V_param'\n",
    "                mad_col = 'mad_param'\n",
    "            elif flux_col == 'f_int_median_scaled_median':\n",
    "                eta_col = 'median_scaled_eta'\n",
    "                V_col = 'median_scaled_V'\n",
    "                mad_col = 'median_scaled_madp'\n",
    "\n",
    "\n",
    "            fig, ax = plt.subplots(4, 2, figsize=(10, 14), sharey=True)\n",
    "            for d, ds in enumerate(DSs):\n",
    "                row = d // 2\n",
    "                col = d % 2\n",
    "\n",
    "                freq = freqs[d]\n",
    "                if freq == 'MFS':\n",
    "                    freq_str = 'MFS'\n",
    "                else:\n",
    "                    freq_str = '{}MHz'.format(freq)\n",
    "                var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                                        'db{1}_ds{2}_{3}.csv'.format(lightcurve_path,\n",
    "                                                                     db,\n",
    "                                                                     ds, ext)))[0]\n",
    "                vp = pd.read_csv(var_params)\n",
    "                vp = vp[vp['detected SN{}'.format(signoise)]=='Yes']\n",
    "\n",
    "                ax[row, col].scatter(np.log10(vp[eta_col]),\n",
    "                                     np.log10(vp[V_col]),\n",
    "                                     marker='.', c='Black')\n",
    "\n",
    "                fb_info = vp[vp['runcat'] == fb_rcats[ds]]\n",
    "                gx_info = vp[vp['runcat'] == gx_rcats[ds]]\n",
    "                psr_info = vp[vp['runcat'] == psr_rcats[ds]]\n",
    "                for df, dataframe in enumerate([fb_info,\n",
    "                                                gx_info,\n",
    "                                                psr_info]):\n",
    "                    cola = [fb_col, gx_col, psr_col][df]\n",
    "                    marka = [fb_mark, gx_mark, psr_mark][df]\n",
    "\n",
    "                    ax[row, col].scatter(np.log10(dataframe[eta_col]),\n",
    "                                         np.log10(dataframe[V_col]),\n",
    "                                         marker=marka, c='none',\n",
    "                                         edgecolor=cola)\n",
    "\n",
    "                if col == 0:\n",
    "                    ax[row, col].set_ylabel(r'log$_{10}$V', fontsize=14)\n",
    "                else:\n",
    "                    ax[row, col].tick_params(axis='y', direction='in')\n",
    "\n",
    "                if row == 3:\n",
    "                    for bob in range(2):\n",
    "                        ax[row, bob].set_xlabel(r'log$_{10}\\eta$',\n",
    "                                              fontsize=14)\n",
    "                else:\n",
    "                    ax[row, col].tick_params(axis='x', direction='in')\n",
    "\n",
    "                ax_text = AnchoredText(freq_str,\n",
    "                                       loc='upper right',\n",
    "                                       prop=dict(size=18, color='Grey'),\n",
    "                                       borderpad=0.1,\n",
    "                                       frameon=False)\n",
    "                ax[row, col].add_artist(ax_text)\n",
    "\n",
    "            leg0 = ax[3, 0].legend(handles=[fb_frame, gx_frame, psr_frame],\n",
    "                                   fontsize=15, frameon=True, loc='lower left', ncol=2,\n",
    "                                   bbox_to_anchor= (0.0, -0.6), borderaxespad=0,\n",
    "                                   edgecolor='Black')\n",
    "\n",
    "            fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "            figure_name = ('{0}Uncorr_EtaVsV_{1}_{2}_SN{3}.png').format(file_path,\n",
    "                                                                      ext,\n",
    "                                                                      flux_col, signoise)\n",
    "            fig.savefig(figure_name, bbox_inches='tight')\n",
    "\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Coefficient Plots\n",
    "\n",
    "Here we're going to plot the correlation coefficients against distance from phase centre in a couple of different ways.\n",
    "\n",
    "### Correlation with and without resolved sources\n",
    "\n",
    "First we plot the correlation coefficients against distance from phase centre where we include all sources ('ES') and then exclude the resolved and artefact sources ('ES')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1658 MHz, ds 49\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1551 MHz, ds 52\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1444 MHz, ds 53\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1337 MHz, ds 50\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1123 MHz, ds 54\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1016 MHz, ds 55\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 909 MHz, ds 51\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on MFS MHz, ds 33\n",
      "Working on f_int f_int_err\n"
     ]
    }
   ],
   "source": [
    "# The minimum signal to noise a source\n",
    "# needs to have (in at least one epoch)\n",
    "# to be included in the analysis\n",
    "minimum_sn = 2.\n",
    "\n",
    "f = 0\n",
    "fc = ['f_int', 'f_int_median_scaled'][f]\n",
    "fc_err = ['f_int_err', 'f_int_median_scaled_err'][f]\n",
    "\n",
    "fig, ax = plt.subplots(8, 2, figsize=(15, 25), sharey=True)\n",
    "\n",
    "for d, ds in enumerate(DSs):\n",
    "    print('----------------------------------')\n",
    "    print('----------------------------------')\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    \n",
    "    print('Working on {0} MHz, ds {1}'.format(freq, ds))\n",
    "    print('Working on {0} {1}'.format(fc, fc_err))\n",
    "    \n",
    "    for e, ext in enumerate(['ES', 'PS']):\n",
    "        col = e\n",
    "        row = d\n",
    "        \n",
    "        correlation_filename = ('{0}AllCorrelations_{1}MHz_'\n",
    "                                '{2}_'\n",
    "                                'db{3}_'\n",
    "                                'ds{4}_'\n",
    "                                '{5}_'\n",
    "                                'minSN{6}.csv').format(file_path,\n",
    "                                                       freq, fc, \n",
    "                                                       db, ds,\n",
    "                                                       ext,\n",
    "                                                       minimum_sn)\n",
    "        \n",
    "        if ext == 'PS':\n",
    "            label_string = 'Resolved sources removed'\n",
    "        elif ext == 'ES':\n",
    "            label_string = 'All detected sources'\n",
    "        ax0_text = AnchoredText('{0}, '\n",
    "                                '{1}'.format(label_string, freq_str),\n",
    "                                loc='lower right',\n",
    "                                prop=dict(size=14, color='Grey'),\n",
    "                                borderpad=0.1,\n",
    "                                frameon=False)\n",
    "        \n",
    "        all_corrs = pd.read_csv(correlation_filename)\n",
    "\n",
    "        ax[row, col].scatter(all_corrs['s1_{}'.format(pc_col)],\n",
    "                             all_corrs['correlation coefficient'],\n",
    "                             marker='.', s=10, c='Black')\n",
    "        ax[row, col].set_xlim(0, 1.27)\n",
    "        \n",
    "        ax[row, col].add_artist(ax0_text)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if col == 0:\n",
    "            ax[row, col].set_xticklabels([0, 0.25, 0.5, 0.75, 1.0])\n",
    "            ax[row, col].set_ylabel('Correlation\\ncoefficient', fontsize=18)\n",
    "        else:\n",
    "            ax[row, col].tick_params(axis='y', direction='in')\n",
    "            ax[row, col].tick_params(labelleft=False)\n",
    "        if row == len(DSs) - 1:\n",
    "            ax[row, col].set_xlabel('Distance to phase centre (deg)', fontsize=18)\n",
    "        else:\n",
    "            ax[row, col].tick_params(axis='x', direction='in')\n",
    "            ax[row, col].tick_params(labelbottom=False)\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "figure_name = ('{0}AllCorrelations_'\n",
    "               'ESvPS_'\n",
    "               '{1}_'\n",
    "               'db{2}_'\n",
    "               'ds{3}_'\n",
    "               'SN{4}.png').format(file_path,\n",
    "                                 fc, \n",
    "                                 db, ds,\n",
    "                                 minimum_sn)\n",
    "fig.savefig(figure_name,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations before and after corrections\n",
    "\n",
    "Now plot the correlation coefficients against distance from phase centre before and after applying the model corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1658 MHz, ds 49\n",
      "Working on f_int f_int_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1551 MHz, ds 52\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1444 MHz, ds 53\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1337 MHz, ds 50\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1123 MHz, ds 54\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1016 MHz, ds 55\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 909 MHz, ds 51\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on MFS MHz, ds 33\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(8, 2, figsize=(15, 25), sharey=True)\n",
    "ext = 'PS'\n",
    "\n",
    "for d, ds in enumerate(DSs):\n",
    "    print('----------------------------------')\n",
    "    print('----------------------------------')\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    \n",
    "    print('Working on {0} MHz, ds {1}'.format(freq, ds))\n",
    "    print('Working on {0} {1}'.format(fc, fc_err))\n",
    "    \n",
    "    for f, fc in enumerate(['f_int', 'f_int_median_scaled']):\n",
    "        fc_err = ['f_int_err', 'f_int_median_scaled_err'][f]\n",
    "\n",
    "        col = f\n",
    "        row = d\n",
    "        \n",
    "        correlation_filename = ('{0}AllCorrelations_{1}MHz_'\n",
    "                                '{2}_'\n",
    "                                'db{3}_'\n",
    "                                'ds{4}_'\n",
    "                                '{5}_'\n",
    "                                'minSN{6}.csv').format(file_path,\n",
    "                                                       freq, fc, \n",
    "                                                       db, ds,\n",
    "                                                       ext,\n",
    "                                                       minimum_sn)\n",
    "        \n",
    "        if fc == 'f_int':\n",
    "            label_string = 'Uncorrected light curves'\n",
    "        elif fc == 'f_int_median_scaled':\n",
    "            label_string = 'Corrected light curves'\n",
    "        ax0_text = AnchoredText('{0}, '\n",
    "                                '{1}'.format(label_string, freq_str),\n",
    "                                loc='lower right',\n",
    "                                prop=dict(size=14, color='Grey'),\n",
    "                                borderpad=0.1,\n",
    "                                frameon=False)\n",
    "        \n",
    "        all_corrs = pd.read_csv(correlation_filename)\n",
    "\n",
    "        ax[row, col].scatter(all_corrs['s1_{}'.format(pc_col)],\n",
    "                             all_corrs['correlation coefficient'],\n",
    "                             marker='.', s=10, c='Black')\n",
    "        ax[row, col].set_xlim(0, 1.27)\n",
    "        \n",
    "        ax[row, col].add_artist(ax0_text)\n",
    "        \n",
    "        if col == 0:\n",
    "            ax[row, col].set_xticklabels([0, 0.25, 0.5, 0.75, 1.0])\n",
    "            ax[row, col].set_ylabel('Correlation\\ncoefficient', fontsize=18)\n",
    "        else:\n",
    "            ax[row, col].tick_params(axis='y', direction='in')\n",
    "            ax[row, col].tick_params(labelleft=False)\n",
    "        if row == len(DSs) - 1:\n",
    "            ax[row, col].set_xlabel('Distance to phase centre (deg)', fontsize=18)\n",
    "        else:\n",
    "            ax[row, col].tick_params(axis='x', direction='in')\n",
    "            ax[row, col].tick_params(labelbottom=False)\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "\n",
    "figure_name = ('{0}AllCorrelations_'\n",
    "               '{1}_'\n",
    "               'UncorrVsCorr_'\n",
    "               '{2}_'\n",
    "               'db{3}_'\n",
    "               'ds{4}_'\n",
    "               'SN{5}.png').format(file_path, ext,\n",
    "                                   fc, \n",
    "                                   db, ds,\n",
    "                                   minimum_sn)\n",
    "fig.savefig(figure_name,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation coefficients - annuli\n",
    "\n",
    "Now plot the correlation coefficients against distance from phase centre before and after applying the model corrections. Here though we plot the correlation coefficients divided up into annuli of the same area. This is to show whether or not the correlations are dependent on distance from phase centre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1658 MHz, ds 49\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1551 MHz, ds 52\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1444 MHz, ds 53\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1337 MHz, ds 50\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1123 MHz, ds 54\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1016 MHz, ds 55\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 909 MHz, ds 51\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on MFS MHz, ds 33\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n"
     ]
    }
   ],
   "source": [
    "max_dpc = 2.0\n",
    "\n",
    "use_area = True\n",
    "step = 0.05\n",
    "area_step = 0.1\n",
    "\n",
    "ext = 'PS'\n",
    "\n",
    "ymins = []\n",
    "ymaxes = []\n",
    "\n",
    "fig, ax = plt.subplots(8, 2, figsize=(15, 25), sharey=True)\n",
    "\n",
    "if use_area:\n",
    "    figure_name = ('{0}Torus_'\n",
    "                   'UncorrVsCorr_'\n",
    "                   'area{1}_'\n",
    "                   '{2}_'\n",
    "                   'SN{3}.png').format(file_path,\n",
    "                                       area_step,\n",
    "                                       ext,\n",
    "                                       minimum_sn)\n",
    "else:\n",
    "    figure_name = ('{0}Torus_'\n",
    "                   'UncorrVsCorr_'\n",
    "                   'radius{1}_'\n",
    "                   '{2}_'\n",
    "                   'SN{3}.png').format(file_path,\n",
    "                                       step,\n",
    "                                       ext,\n",
    "                                       minimum_sn)\n",
    "\n",
    "for d, ds in enumerate(DSs):\n",
    "    \n",
    "    \n",
    "    print('----------------------------------')\n",
    "    print('----------------------------------')\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    print('Working on {0} MHz, ds {1}'.format(freq, ds))\n",
    "    for f, fc in enumerate(['f_int', 'f_int_median_scaled']):\n",
    "        fc_err = ['f_int_err', 'f_int_median_scaled_err'][f]\n",
    "        print('Working on {0} {1}'.format(fc, fc_err))\n",
    "\n",
    "        r1 = 0.\n",
    "\n",
    "        col = f\n",
    "        row = d\n",
    "\n",
    "        correlation_filename = ('{0}AllCorrelations_{1}MHz_'\n",
    "                                '{2}_'\n",
    "                                'db{3}_'\n",
    "                                'ds{4}_'\n",
    "                                '{5}_'\n",
    "                                'minSN{6}.csv').format(file_path,\n",
    "                                                       freq, fc, \n",
    "                                                       db, ds,\n",
    "                                                       ext,\n",
    "                                                       minimum_sn)\n",
    "\n",
    "        \n",
    "        if fc == 'f_int':\n",
    "            label_string = 'Uncorrected light curves'\n",
    "        elif fc == 'f_int_median_scaled':\n",
    "            label_string = 'Corrected light curves'\n",
    "        ax0_text = AnchoredText('{0}, '\n",
    "                                '{1}'.format(label_string, freq_str),\n",
    "                                loc='lower right',\n",
    "                                prop=dict(size=14, color='Grey'),\n",
    "                                borderpad=0.1,\n",
    "                                frameon=False)\n",
    "\n",
    "        all_corrs = pd.read_csv(correlation_filename)\n",
    "        r1s = []\n",
    "\n",
    "        count = 0\n",
    "        while r1 < max_dpc:\n",
    "            r1s.append(r1)\n",
    "            if use_area:\n",
    "                r2 = annulus_outer_r(r1, area_step)\n",
    "            else:\n",
    "                r2 = r1 + step\n",
    "\n",
    "            qry = '{0} < s1_{1} <= {2} and {0} < s2_{1} <= {2}'.format(r1, pc_col, r2)\n",
    "            annulus = all_corrs.query(qry)\n",
    "\n",
    "            ax[row, col].scatter(annulus['s1_{}'.format(pc_col)],\n",
    "                                 annulus['correlation coefficient'],\n",
    "                                 marker='.', s=12)\n",
    "\n",
    "            r1 = r2\n",
    "            count += 1\n",
    "\n",
    "        ax[row, col].set_xlim(0, 1.3)\n",
    "        \n",
    "        ax[row, col].add_artist(ax0_text)\n",
    "        \n",
    "        if col == 0:\n",
    "            ax[row, col].set_xticklabels([0, 0.25, 0.5, 0.75, 1.0])\n",
    "            ax[row, col].set_ylabel('Correlation\\ncoefficient', fontsize=18)\n",
    "        else:\n",
    "            ax[row, col].tick_params(axis='y', direction='in')\n",
    "            ax[row, col].tick_params(labelleft=False)\n",
    "        if row == len(DSs) - 1:\n",
    "            ax[row, col].set_xlabel('Distance to phase centre (deg)', fontsize=18)\n",
    "        else:\n",
    "            ax[row, col].tick_params(axis='x', direction='in')\n",
    "            ax[row, col].tick_params(labelbottom=False)\n",
    "\n",
    "        ymin, ymax = ax[row, col].get_ylim()\n",
    "        ymins.append(ymin)\n",
    "        ymaxes.append(ymax)\n",
    "\n",
    "    ymin = np.min(np.array(ymins)) - 0.02\n",
    "    ymax = np.max(np.array(ymaxes)) + 0.02\n",
    "    for a in range(2):        \n",
    "        for r in r1s:\n",
    "            ax[row, a].plot(np.ones(10)*r,\n",
    "                            np.linspace(ymin-50, ymax+50, 10),\n",
    "                            '--', alpha=0.2,\n",
    "                            c='Grey', zorder=0, lw=2)\n",
    "\n",
    "        ax[row, a].set_ylim(ymin, ymax)    \n",
    "\n",
    "    fig.subplots_adjust(hspace=0, wspace=0)\n",
    "    \n",
    "fig.savefig(figure_name,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile-Quantile plots\n",
    "\n",
    "Here we see whether the distribution of correlation coefficients in each band is normally distributed, using quantile-quantile or Q-Q plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1658 MHz, ds 49\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1551 MHz, ds 52\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1444 MHz, ds 53\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1337 MHz, ds 50\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1123 MHz, ds 54\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1016 MHz, ds 55\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 909 MHz, ds 51\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on MFS MHz, ds 33\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n"
     ]
    }
   ],
   "source": [
    "ext = 'PS'\n",
    "for d, ds in enumerate(DSs):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True, sharex=True)\n",
    "    print('----------------------------------')\n",
    "    print('----------------------------------')\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    print('Working on {0} MHz, ds {1}'.format(freq, ds))\n",
    "    \n",
    "    figure_name = ('{0}QQPlot_'\n",
    "                   '{1}MHz_'\n",
    "                   'db{2}_'\n",
    "                   'ds{3}_'\n",
    "                   '{4}_'\n",
    "                   'SN{5}.png').format(file_path,\n",
    "                                       freq,\n",
    "                                       db, ds,\n",
    "                                       ext,\n",
    "                                       minimum_sn)\n",
    "\n",
    "    for f, fc in enumerate(['f_int', 'f_int_median_scaled']):\n",
    "        fc_err = ['f_int_err', 'f_int_median_scaled_err'][f]\n",
    "        print('Working on {0} {1}'.format(fc, fc_err))\n",
    "\n",
    "        correlation_filename = ('{0}AllCorrelations_{1}MHz_'\n",
    "                                '{2}_'\n",
    "                                'db{3}_'\n",
    "                                'ds{4}_'\n",
    "                                '{5}_'\n",
    "                                'minSN{6}.csv').format(file_path,\n",
    "                                                       freq, fc, \n",
    "                                                       db, ds,\n",
    "                                                       ext,\n",
    "                                                       minimum_sn)\n",
    "        \n",
    "        all_corrs = pd.read_csv(correlation_filename)\n",
    "        \n",
    "        if fc == 'f_int':\n",
    "            label_string = 'Uncorrected light curves, {0}'.format(freq_str)\n",
    "        elif fc == 'f_int_median_scaled':\n",
    "            label_string = 'Corrected light curves, {0}'.format(freq_str)\n",
    "        ax0_text = AnchoredText(label_string,\n",
    "                                loc='lower right',\n",
    "                                prop=dict(size=16, color='Grey'),\n",
    "                                borderpad=0.1,\n",
    "                                frameon=False)\n",
    "        \n",
    "        ax[f].add_artist(ax0_text)\n",
    "        \n",
    "        res = spstats.probplot(all_corrs['correlation coefficient'], plot=ax[f])\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    fig.savefig(figure_name,\n",
    "                bbox_inches='tight')\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux dependence of the correlations\n",
    "\n",
    "Here we plot the flux densities of each pair of sources and show the correlation coefficients as colours. We do this for the uncorrected and corrected light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1658 MHz, ds 49\n",
      "Working on f_int f_int_err\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/driessen/.conda/envs/LaurasJupyter36/lib/python3.6/site-packages/pandas/core/series.py:679: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1551 MHz, ds 52\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1444 MHz, ds 53\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1337 MHz, ds 50\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1123 MHz, ds 54\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 1016 MHz, ds 55\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 909 MHz, ds 51\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on MFS MHz, ds 33\n",
      "Working on f_int f_int_err\n",
      "Working on f_int_median_scaled f_int_median_scaled_err\n"
     ]
    }
   ],
   "source": [
    "ext = 'PS'\n",
    "fig, ax = plt.subplots(8, 2, figsize=(14, 26), sharex=True, sharey=True)\n",
    "figure_name = ('{0}FluxPlot_'\n",
    "               '{1}_'\n",
    "               'SN{2}.png').format(file_path,\n",
    "                                   ext,\n",
    "                                   minimum_sn)\n",
    "\n",
    "for d, ds in enumerate(DSs):\n",
    "    print('----------------------------------')\n",
    "    print('----------------------------------')\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    print('Working on {0} MHz, ds {1}'.format(freq, ds))\n",
    "    for f, fc in enumerate(['f_int', 'f_int_median_scaled']):\n",
    "        fc_err = ['f_int_err', 'f_int_median_scaled_err'][f]\n",
    "        print('Working on {0} {1}'.format(fc, fc_err))\n",
    "\n",
    "        correlation_filename = ('{0}AllCorrelations_{1}MHz_'\n",
    "                                '{2}_'\n",
    "                                'db{3}_'\n",
    "                                'ds{4}_'\n",
    "                                '{5}_'\n",
    "                                'minSN{6}.csv').format(file_path,\n",
    "                                                       freq, fc, \n",
    "                                                       db, ds,\n",
    "                                                       ext,\n",
    "                                                       minimum_sn)\n",
    "        \n",
    "        all_corrs = pd.read_csv(correlation_filename)\n",
    "        \n",
    "        all_corrs = all_corrs.sort_values(by=['s1_median_{}'.format(fc),\n",
    "                                              's2_median_{}'.format(fc)])\n",
    "        leg_5 = all_corrs.query('`correlation coefficient` <= 0.5')\n",
    "\n",
    "        ax[d, f].scatter(np.log10(leg_5['s1_median_{}'.format(fc)]),\n",
    "                      np.log10(leg_5['s2_median_{}'.format(fc)]),\n",
    "                      c='Black', marker='.')\n",
    "        \n",
    "        geq_5 = all_corrs.query(('`correlation coefficient` > 0.5 and '\n",
    "                                 '`correlation coefficient` <= 0.6'))\n",
    "        geq_6 = all_corrs.query(('`correlation coefficient` > 0.6 and '\n",
    "                                 '`correlation coefficient` <= 0.7'))\n",
    "        geq_7 = all_corrs.query(('`correlation coefficient` > 0.7 and '\n",
    "                                 '`correlation coefficient` <= 0.8'))\n",
    "        geq_8 = all_corrs.query(('`correlation coefficient` > 0.8'))\n",
    "        \n",
    "        ax[d, f].scatter(np.log10(geq_5['s1_median_{}'.format(fc)]),\n",
    "                      np.log10(geq_5['s2_median_{}'.format(fc)]),\n",
    "                      c='DarkGrey', marker='.')\n",
    "        ax[d, f].scatter(np.log10(geq_6['s1_median_{}'.format(fc)]),\n",
    "                      np.log10(geq_6['s2_median_{}'.format(fc)]),\n",
    "                      c='Yellow', marker='.')\n",
    "        ax[d, f].scatter(np.log10(geq_7['s1_median_{}'.format(fc)]),\n",
    "                      np.log10(geq_7['s2_median_{}'.format(fc)]),\n",
    "                      c='Orange', marker='.')\n",
    "        ax[d, f].scatter(np.log10(geq_8['s1_median_{}'.format(fc)]),\n",
    "                      np.log10(geq_8['s2_median_{}'.format(fc)]),\n",
    "                      c='Red', marker='.')\n",
    "        \n",
    "        if fc == 'f_int':\n",
    "            label_string = 'Uncorrected light curves'\n",
    "        elif fc == 'f_int_median_scaled':\n",
    "            label_string = 'Corrected light curves'\n",
    "        ax0_text = AnchoredText('{0}, '\n",
    "                                '{1}'.format(label_string, freq_str),\n",
    "                                loc='lower right',\n",
    "                                prop=dict(size=14, color='Grey'),\n",
    "                                borderpad=0.1,\n",
    "                                frameon=False)\n",
    "        \n",
    "        if f == 0:\n",
    "            ax[d, f].set_ylabel(r'log$_{10}$Flux density\\n[Jy]', fontsize=16)\n",
    "        else:\n",
    "            ax[d, f].tick_params(axis='y', direction='in')\n",
    "            ax[d, f].tick_params(labelleft=False)\n",
    "        if d == 7:\n",
    "            ax[d, f].set_xlabel(r'log$_{10}$Flux density [Jy]', fontsize=16)\n",
    "        else:\n",
    "            ax[d, f].tick_params(axis='x', direction='in')\n",
    "            ax[d, f].tick_params(labelbottom=False)\n",
    "        \n",
    "        ax[d, f].add_artist(ax0_text)\n",
    "            \n",
    "pointsize = 5\n",
    "black_dot = mlines.Line2D([], [], color='None',\n",
    "                          marker='o',\n",
    "                          markerfacecolor='Black',\n",
    "                          markeredgecolor='Black',\n",
    "                          markersize=pointsize+5,\n",
    "                          label='Correlation coefficient < 0.5')\n",
    "grey_dot = mlines.Line2D([], [], color='None',\n",
    "                          marker='o',\n",
    "                          markerfacecolor='DarkGrey',\n",
    "                          markeredgecolor='DarkGrey',\n",
    "                          markersize=pointsize+5,\n",
    "                          label='0.5 < Correlation coefficient < 0.6')\n",
    "yellow_dot = mlines.Line2D([], [], color='None',\n",
    "                          marker='o',\n",
    "                          markerfacecolor='Yellow',\n",
    "                          markeredgecolor='Yellow',\n",
    "                          markersize=pointsize+5,\n",
    "                          label='0.6 < Correlation coefficient < 0.7')\n",
    "orange_dot = mlines.Line2D([], [], color='None',\n",
    "                          marker='o',\n",
    "                          markerfacecolor='Orange',\n",
    "                          markeredgecolor='Orange',\n",
    "                          markersize=pointsize+5,\n",
    "                          label='0.7 < Correlation coefficient < 0.8')\n",
    "red_dot = mlines.Line2D([], [], color='None',\n",
    "                          marker='o',\n",
    "                          markerfacecolor='Red',\n",
    "                          markeredgecolor='Red',\n",
    "                          markersize=pointsize+5,\n",
    "                          label='0.8 < Correlation coefficient')\n",
    "\n",
    "leg0 = ax[7, 0].legend(handles=[black_dot, grey_dot, yellow_dot, orange_dot, red_dot],\n",
    "                       fontsize=15, frameon=True, loc='lower left', ncol=2,\n",
    "                       bbox_to_anchor= (0.0, -0.75), borderaxespad=0,\n",
    "                       edgecolor='Black')\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "fig.savefig(figure_name, bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known variable light curves\n",
    "\n",
    "Here we plot the light curves of GX 339-4, MKT J170456.2-482100, and PSR J1703-4851 before and after applying the model corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 33\n",
    "ext = 'PS'\n",
    "fb_file = glob.glob(('{0}rcat{1}_'\n",
    "                     'ra*_dec*_'\n",
    "                     'db{2}_ds{3}_'\n",
    "                     '{4}.csv').format(lightcurve_path,\n",
    "                                       int(fb_rcats[ds]),\n",
    "                                       db,\n",
    "                                       ds,\n",
    "                                       ext))[0]\n",
    "fb_info = pd.read_csv(fb_file)\n",
    "gx_file = glob.glob(('{0}rcat{1}_'\n",
    "                     'ra*_dec*_'\n",
    "                     'db{2}_ds{3}_'\n",
    "                     '{4}.csv').format(lightcurve_path,\n",
    "                                       int(gx_rcats[ds]),\n",
    "                                       db,\n",
    "                                       ds,\n",
    "                                       ext))[0]\n",
    "gx_info = pd.read_csv(gx_file)\n",
    "psr_file = glob.glob(('{0}rcat{1}_'\n",
    "                      'ra*_dec*_'\n",
    "                      'db{2}_ds{3}_'\n",
    "                      '{4}.csv').format(lightcurve_path,\n",
    "                                        int(psr_rcats[ds]),\n",
    "                                        db,\n",
    "                                        ds,\n",
    "                                        ext))[0]\n",
    "psr_info = pd.read_csv(psr_file)\n",
    "\n",
    "flux_col = 'f_int'\n",
    "flux_err = 'f_int_err'\n",
    "mjd_col = 'mjd'\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "for df, dataframe in enumerate([fb_info,\n",
    "                            gx_info,\n",
    "                            psr_info]):\n",
    "    for flux_col in ['f_int', 'f_int_median_scaled']:\n",
    "        if flux_col == 'f_int':\n",
    "            cola = [fb_col, gx_col, psr_col][df]\n",
    "            ax[df].errorbar(dataframe[mjd_col], dataframe[flux_col]*1e3,\n",
    "                            yerr=dataframe[flux_err]*1e3, fmt='o', c=cola,\n",
    "                            markersize=8,\n",
    "                            label='Uncorrected light curve')\n",
    "        else:\n",
    "            cola = ['#C82D35', '#256E7E', '#1C1862'][df]\n",
    "            ax[df].errorbar(dataframe[mjd_col], dataframe[flux_col]*1e3,\n",
    "                            yerr=dataframe[flux_err]*1e3, fmt='o', c=cola,\n",
    "                            markersize=6,\n",
    "                            label='Corrected light curve')\n",
    "\n",
    "    name = ['(a) MKT J170456.2-482100',\n",
    "            '(b) GX 339-4',\n",
    "            '(c) PSR J1703-4851'][df]\n",
    "    legend = ax[df].legend(loc='upper right', fontsize=12)\n",
    "    legend.set_title(name, prop={'size':14})\n",
    "    legend._legend_box.align = \"left\"\n",
    "\n",
    "for a in range(2):\n",
    "    ax[a].tick_params(axis='x', direction='in')\n",
    "    ax[a].tick_params(labelbottom=False)\n",
    "for a in range(3):\n",
    "    ax[a].set_ylabel('Flux density [mJy]', fontsize=20)\n",
    "ax[2].set_xlabel('MJD', fontsize=22)\n",
    "\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.savefig('{0}KnownVariables_LightCurves.png'.format(file_path),\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairs of highly correlated sources\n",
    "\n",
    "Here we plot pairs of highly correlated (Pearson's r correlation coefficient greater than 0.85) from the 909 MHz subband."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 909 MHz, ds 51\n",
      "Working on f_int f_int_err\n"
     ]
    }
   ],
   "source": [
    "ext = 'ES'\n",
    "for d, ds in enumerate(DSs[6:7], 6):\n",
    "    print('----------------------------------')\n",
    "    print('----------------------------------')\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    print('Working on {0} MHz, ds {1}'.format(freq, ds))\n",
    "\n",
    "    for f, fc in enumerate(['f_int', 'f_int_median_scaled'][:1]):\n",
    "        fc_err = ['f_int_err', 'f_int_median_scaled_err'][f]\n",
    "        print('Working on {0} {1}'.format(fc, fc_err))\n",
    "\n",
    "        correlation_filename = ('{0}AllCorrelations_{1}MHz_'\n",
    "                                '{2}_'\n",
    "                                'db{3}_'\n",
    "                                'ds{4}_'\n",
    "                                '{5}_'\n",
    "                                'minSN{6}.csv').format(file_path,\n",
    "                                                       freq, fc, \n",
    "                                                       db, ds,\n",
    "                                                       ext,\n",
    "                                                       minimum_sn)\n",
    "        \n",
    "        all_corrs = pd.read_csv(correlation_filename)\n",
    "\n",
    "qry = '`correlation coefficient` > 0.85'\n",
    "bob = all_corrs.query(qry)\n",
    "unique_rcats = pd.concat([bob['s1_runcat'],\n",
    "                          bob['s2_runcat']]).unique()\n",
    "\n",
    "bob_rcats = []\n",
    "for r, row in bob.iterrows():\n",
    "    bob_rcats.append([row['s1_runcat'],\n",
    "                      row['s2_runcat'],\n",
    "                      row['correlation coefficient']])\n",
    "bob_rcats = np.array(bob_rcats)\n",
    "unique_s1_index = np.unique(bob_rcats[:, 0], return_index=True)\n",
    "bob_rcats = bob_rcats[unique_s1_index[1]]\n",
    "\n",
    "ext = 'ES'\n",
    "fig, ax = plt.subplots(8, 1, figsize=(10, 20), sharex=True)\n",
    "col = ['Black', 'Grey']\n",
    "mss = [30, 20]\n",
    "count = 0\n",
    "for r, row in enumerate(bob_rcats):\n",
    "    medians = []\n",
    "    for a in range(2):\n",
    "        filename = glob.glob(('{0}rcat{1}_'\n",
    "                              'ra*_dec*_'\n",
    "                              'db{2}_ds{3}_'\n",
    "                              '{4}.csv').format(lightcurve_path,\n",
    "                                                int(row[a]),\n",
    "                                                db,\n",
    "                                                ds,\n",
    "                                                ext))[0]\n",
    "        source_info = pd.read_csv(filename)\n",
    "        medians.append(np.nanmedian(source_info['f_int']))\n",
    "\n",
    "    if ((medians[0]/medians[1]>0.5) and\n",
    "        (medians[0]/medians[1]<1.5) and\n",
    "        count<8):\n",
    "        for a in range(2):\n",
    "            filename = glob.glob(('{0}rcat{1}_'\n",
    "                                  'ra*_dec*_'\n",
    "                                  'db{2}_ds{3}_'\n",
    "                                  '{4}.csv').format(lightcurve_path,\n",
    "                                                    int(row[a]),\n",
    "                                                    db,\n",
    "                                                    ds,\n",
    "                                                    ext))[0]\n",
    "            source_info = pd.read_csv(filename)\n",
    "            ax[count].scatter(source_info['mjd'], source_info['f_int']*1e3, s=mss[a], c=col[a])\n",
    "\n",
    "        ax0_text = AnchoredText('r = {:.3f}'.format(row[2]),\n",
    "                                loc='upper left',\n",
    "                                prop=dict(size=14, color='Grey'),\n",
    "                                borderpad=0.05,\n",
    "                                frameon=True)\n",
    "        ax[count].add_artist(ax0_text)\n",
    "        count += 1\n",
    "\n",
    "for a in range(7):\n",
    "    ax[a].tick_params(axis='x', direction='in')\n",
    "    ax[a].tick_params(labelbottom=False)\n",
    "for a in range(8):\n",
    "    ax[a].set_ylabel('Flux density\\n[mJy]', fontsize=18)\n",
    "ax[7].set_xlabel('MJD', fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.savefig('{0}CorrelationDemo_LightCurves.png'.format(file_path),\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example corrected light curves\n",
    "\n",
    "Here we plot some sources from the 909 MHz band to demonstrate the effect of the corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "----------------------------------\n",
      "Working on 909 MHz, ds 51\n",
      "Working on f_int f_int_err\n"
     ]
    }
   ],
   "source": [
    "ext = 'PS'\n",
    "for d, ds in enumerate(DSs[6:7], 6):\n",
    "    print('----------------------------------')\n",
    "    print('----------------------------------')\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = 'MFS'\n",
    "    else:\n",
    "        freq_str = '{}MHz'.format(freq)\n",
    "    print('Working on {0} MHz, ds {1}'.format(freq, ds))\n",
    "\n",
    "    for f, fc in enumerate(['f_int', 'f_int_median_scaled'][:1]):\n",
    "        fc_err = ['f_int_err', 'f_int_median_scaled_err'][f]\n",
    "        print('Working on {0} {1}'.format(fc, fc_err))\n",
    "\n",
    "        var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                                'db{1}_ds{2}_{3}.csv'.format(lightcurve_path,\n",
    "                                                             db,\n",
    "                                                             ds, ext)))[0]\n",
    "        vp_all = pd.read_csv(var_params)\n",
    "        vp_sn2 = vp_all[vp_all['detected SN2']=='Yes']\n",
    "\n",
    "qry = 'eta_param > 0.8 and median_scaled_eta < 0.8'\n",
    "bob = vp_sn2.query(qry)\n",
    "\n",
    "bob_rcats = []\n",
    "for r, row in bob.iterrows():\n",
    "    bob_rcats.append(row['runcat'])\n",
    "bob_rcats = np.array(bob_rcats)\n",
    "\n",
    "ext = 'PS'\n",
    "fig, ax = plt.subplots(4, 2, figsize=(16, 12), sharex=True, sharey='row')\n",
    "col = ['Black', 'Grey']\n",
    "for r, row in enumerate([153385, 152744, 148925, 148377]):\n",
    "    filename = glob.glob(('{0}rcat{1}_'\n",
    "                          'ra*_dec*_'\n",
    "                          'db{2}_ds{3}_'\n",
    "                          '{4}.csv').format(lightcurve_path,\n",
    "                                            int(row),\n",
    "                                            db,\n",
    "                                            ds,\n",
    "                                            ext))[0]\n",
    "    source_info = pd.read_csv(filename)\n",
    "    ax[r, 0].errorbar(source_info['mjd'],\n",
    "                       source_info['f_int']*1e3,\n",
    "                       yerr=source_info['f_int_err']*1e3,\n",
    "                       fmt='o', c='Black')\n",
    "    ax[r, 1].errorbar(source_info['mjd'],\n",
    "                       source_info['f_int_median_scaled']*1e3,\n",
    "                       yerr=source_info['f_int_median_scaled_err']*1e3,\n",
    "                       c='Black', fmt='o')\n",
    "    \n",
    "    a = 0\n",
    "    xmin, xmax = ax[r, a].get_xlim()\n",
    "    ax[r, a].plot(np.linspace(xmin, xmax, 10),\n",
    "                  np.ones(10)*np.nanmedian(source_info['f_int']*1e3),\n",
    "                  '--', c='Black', alpha=0.4, lw=3)\n",
    "    ax[r, a].set_xlim(xmin, xmax)\n",
    "    a = 1\n",
    "    xmin, xmax = ax[r, a].get_xlim()\n",
    "    ax[r, a].plot(np.linspace(xmin, xmax, 10),\n",
    "                  np.ones(10)*np.nanmedian(source_info['f_int_median_scaled']*1e3),\n",
    "                  '--', c='Black', alpha=0.4, lw=3)\n",
    "    ax[r, a].set_xlim(xmin, xmax)\n",
    "    \n",
    "    c1_text = (r'$\\eta$={0:.4f} $V$={1:.4f} $\\xi$={2:.4f}').format(np.nanmedian(source_info['eta_param']),\n",
    "                                       np.nanmedian(source_info['V_param']),\n",
    "                                       np.nanmedian(source_info['mad_param']))\n",
    "    c2_text = r'$\\eta$={0:.4f} $V$={1:.4f} $\\xi$={2:.4f}'.format(np.nanmedian(source_info['median_scaled_eta']),\n",
    "                                                     np.nanmedian(source_info['median_scaled_V']),\n",
    "                                                     np.nanmedian(source_info['median_scaled_madp']))\n",
    "    \n",
    "    ax1_text = AnchoredText(c1_text,\n",
    "                            loc='upper left',\n",
    "                            prop=dict(size=16, color='Grey'),\n",
    "                            borderpad=0.05,\n",
    "                            frameon=False)\n",
    "    ax[r, 0].add_artist(ax1_text)\n",
    "    ax2_text = AnchoredText(c2_text,\n",
    "                            loc='upper left',\n",
    "                            prop=dict(size=16, color='Grey'),\n",
    "                            borderpad=0.03,\n",
    "                            frameon=False)\n",
    "    ax[r, 1].add_artist(ax2_text)\n",
    "\n",
    "    ax00_text = AnchoredText('Uncorrected light curves',\n",
    "                            loc='lower right',\n",
    "                            prop=dict(size=14, color='Grey'),\n",
    "                            borderpad=0.1,\n",
    "                            frameon=False)\n",
    "    ax11_text = AnchoredText('Corrected light curves',\n",
    "                            loc='lower right',\n",
    "                            prop=dict(size=14, color='Grey'),\n",
    "                            borderpad=0.1,\n",
    "                            frameon=False)\n",
    "    ax[r, 0].add_artist(ax00_text)\n",
    "    ax[r, 1].add_artist(ax11_text)\n",
    "\n",
    "for a in range(3):\n",
    "    ax[a, 0].tick_params(axis='x', direction='in')\n",
    "    ax[a, 0].tick_params(labelbottom=False)\n",
    "    ax[a, 1].tick_params(axis='x', direction='in')\n",
    "    ax[a, 1].tick_params(labelbottom=False)\n",
    "for a in range(4):\n",
    "    ax[a, 0].set_ylabel('Flux density\\n[mJy]', fontsize=18)\n",
    "    ax[a, 1].tick_params(axis='y', direction='in')\n",
    "    ax[a, 1].tick_params(labelleft=False)\n",
    "ax[3, 0].set_xlabel('MJD', fontsize=20)\n",
    "ax[3, 1].set_xlabel('MJD', fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "fig.savefig('{0}CorrectionDemo_LightCurves.png'.format(file_path), bbox_inches='tight')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables\n",
    "\n",
    "We have two tables in the report/thesis. Here's where we print those values.\n",
    "\n",
    "### Number of sources in the field per subband\n",
    "\n",
    "Simply printing the number of unresolved sources in each subband with different signal to noise values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658\\,MHz & 4321 & 1281 & 193 \\\\\n",
      "1551\\,MHz & 4321 & 1630 & 232 \\\\\n",
      "1444\\,MHz & 4321 & 2064 & 455 \\\\\n",
      "1337\\,MHz & 4321 & 2161 & 433 \\\\\n",
      "1123\\,MHz & 4321 & 2213 & 494 \\\\\n",
      "1016\\,MHz & 4321 & 2565 & 638 \\\\\n",
      "909\\,MHz & 4321 & 1996 & 455 \\\\\n",
      "1283\\,MHz (MFS) & 4325 & 3608 & 1080 \\\\\n"
     ]
    }
   ],
   "source": [
    "ext = 'PS'\n",
    "for d, ds in enumerate(DSs):\n",
    "    freq = freqs[d]\n",
    "    if freq == 'MFS':\n",
    "        freq_str = '1283\\,MHz (MFS)'\n",
    "    else:\n",
    "        freq_str = '{}\\,MHz'.format(freq)\n",
    "    var_params = glob.glob(('{0}VariabilityParams_'\n",
    "                            'db{1}_ds{2}_{3}.csv'.format(lightcurve_path,\n",
    "                                                         db,\n",
    "                                                         ds, ext)))[0]\n",
    "    vp_all = pd.read_csv(var_params)\n",
    "    \n",
    "    vp_2 = vp_all[vp_all['detected SN2'] == 'Yes']\n",
    "    vp_3 = vp_all[vp_all['detected SN3'] == 'Yes']\n",
    "    \n",
    "    print('{0} & {1} & {2} & {3} \\\\\\\\'.format(freq_str,\n",
    "                                              len(vp_all.index),\n",
    "                                              len(vp_2.index),\n",
    "                                              len(vp_3.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of outlier correlations\n",
    "\n",
    "Here we print the number of correlation values outside of a number of standard deviations, both theoreticially and experimentally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658 & 2280 & 2213.40 & 2017 & 2213.40 & 138 & 51.93 & 66 & 51.93 & 37 & 0.47 & 18 & 0.47 \\\\\n",
      "1551 & 4046 & 3584.34 & 3668 & 3584.34 & 175 & 84.10 & 123 & 84.10 & 5 & 0.76 & 6 & 0.76 \\\\\n",
      "1444 & 6815 & 5747.91 & 5164 & 5747.91 & 1015 & 134.86 & 243 & 134.86 & 336 & 1.22 & 70 & 1.22 \\\\\n",
      "1337 & 6349 & 6301.00 & 5655 & 6301.00 & 550 & 147.83 & 223 & 147.83 & 138 & 1.34 & 54 & 1.34 \\\\\n",
      "1123 & 7283 & 6607.96 & 8154 & 6607.96 & 224 & 155.04 & 267 & 155.04 & 16 & 1.40 & 20 & 1.40 \\\\\n",
      "1016 & 9103 & 8877.82 & 8458 & 8877.82 & 904 & 208.29 & 611 & 208.29 & 321 & 1.89 & 195 & 1.89 \\\\\n",
      "909 & 5270 & 5375.32 & 4925 & 5375.32 & 469 & 126.12 & 268 & 126.12 & 149 & 1.14 & 85 & 1.14 \\\\\n",
      "MFS & 25167 & 17567.65 & 16769 & 17567.65 & 4734 & 412.17 & 1106 & 412.17 & 1472 & 3.73 & 342 & 3.73 \\\\\n"
     ]
    }
   ],
   "source": [
    "for d, ds in enumerate(DSs):\n",
    "    ext = 'PS'\n",
    "    freq = freqs[d]\n",
    "    try:\n",
    "        row = [int(freq)]\n",
    "    except ValueError:\n",
    "        row = [freq]\n",
    "\n",
    "    for num_std in [3, 4, 5]:\n",
    "        for f, fc in enumerate(['f_int', 'f_int_median_scaled']):\n",
    "            fc_err = '{}_err'.format(fc)\n",
    "            correlation_filename = ('{0}AllCorrelations_{1}MHz_'\n",
    "                                    '{2}_'\n",
    "                                    'db{3}_'\n",
    "                                    'ds{4}_'\n",
    "                                    '{5}_'\n",
    "                                    'minSN{6}.csv').format(file_path,\n",
    "                                                           freq, fc, \n",
    "                                                           db, ds,\n",
    "                                                           ext,\n",
    "                                                           minimum_sn)\n",
    "            all_corrs = pd.read_csv(correlation_filename)\n",
    "            corr_coeffs = all_corrs['correlation coefficient']\n",
    "            \n",
    "            mean_ = np.nanmean(corr_coeffs)\n",
    "            std_ = np.nanstd(corr_coeffs)\n",
    "            total_length = len(np.array(corr_coeffs))\n",
    "            \n",
    "            rv = spstats.norm(mean_, std_)\n",
    "            \n",
    "            theory = 1. - (rv.cdf(mean_+num_std*std_) - rv.cdf(mean_-num_std*std_))\n",
    "            num_outliers = (len(np.where(np.logical_or(corr_coeffs<mean_-num_std*std_,\n",
    "                                                       corr_coeffs>mean_+num_std*std_))[0]))\n",
    "            \n",
    "            row.append(num_outliers)\n",
    "            row.append(theory * total_length)\n",
    "    print(('{0} & '\n",
    "           '{1} & {2:.2f} & '\n",
    "           '{3} & {4:.2f} & '\n",
    "           '{5} & {6:.2f} & '\n",
    "           '{7} & {8:.2f} & '\n",
    "           '{9} & {10:.2f} & '\n",
    "           '{11} & {12:.2f} \\\\\\\\').format(row[0],\n",
    "                                          row[1], row[2], row[3], row[4],\n",
    "                                          row[5], row[6], row[7], row[8],\n",
    "                                          row[9], row[10], row[11], row[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
